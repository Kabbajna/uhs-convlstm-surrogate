# Final Codes Index - Complete Overview

üìÅ **Location**: `/Users/narjisse/Documents/Effat Courses/deeponet/final_codes_github/`

---

## ‚úÖ All Files Ready for GitHub

### Configuration Files

| File | Purpose | Status |
|------|---------|--------|
| `config_shared.py` | Shared configuration (SEED, splits, hyperparameters) | ‚úÖ Ready |
| `verify_consistency.py` | Verification script to check all configs match | ‚úÖ Ready |
| `README_CODES.md` | Main documentation for this folder | ‚úÖ Ready |
| `INDEX.md` | This file | ‚úÖ Ready |

### Main Training Scripts (4 models for comparison)

| File | Model | R¬≤ (15-month) | Parameters | Status |
|------|-------|---------------|------------|--------|
| `01_ConvLSTM_UNet_ScheduledSampling.py` | ConvLSTM SS ‚≠ê | **0.990** | 21.38M | ‚úÖ Ready |
| `02_ConvLSTM_UNet_TeacherForcing.py` | ConvLSTM TF | 0.071 ‚ùå | 21.38M | ‚úÖ Ready |
| `03_3D_UNet_Baseline.py` | 3D U-Net | -0.55 ‚ùå | 22.58M | ‚úÖ Ready |
| `04_FNO_Baseline.py` | FNO 3D | -4.40 ‚ùå | 21.27M | ‚úÖ Ready |

### Ablation Studies (3 studies)

| File | What's Ablated | Expected Impact | Status |
|------|----------------|-----------------|--------|
| `ablation_A.py` | Œª_sat = 0 (no saturation conservation) | Sg + Sw ‚â† 1 violations | ‚úÖ Ready |
| `ablation_B.py` | Œª_mass = 0 (no mass conservation) | Unphysical saturation changes | ‚úÖ Ready |
| `ablation_C.py` | Œª_darcy = 0 (no Darcy constraint) | Spatial artifacts | ‚úÖ Ready |

---

## Consistency Verification Results

```bash
cd final_codes_github
python3 verify_consistency.py
```

**Output**:
```
‚úÖ SEED = 42 pour tous les mod√®les
‚úÖ Split 70/15/15 pour tous les mod√®les
‚úÖ Learning rate = 1e-4 pour tous les mod√®les
‚úÖ Epochs = 40 pour tous les mod√®les
‚úÖ Base features = 32 pour tous les mod√®les
‚úÖ Tous les fichiers pr√©sents
```

---

## Shared Configuration Summary

All 7 Python files use these **IDENTICAL** configurations:

```python
SEED = 42
TRAIN_SPLIT = 0.70  # 70%
VAL_SPLIT = 0.15    # 15%
TEST_SPLIT = 0.15   # 15%

NUM_EPOCHS = 40
BATCH_SIZE = 1
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-5

BASE_FEATURES = 32  # For ConvLSTM and UNet
FNO_WIDTH = 32
FNO_MODES = [8, 8, 4]

SEQUENCE_LENGTH_TRAIN = 10
SEQUENCE_LENGTH_TEST = 33

LAMBDA_SAT = 0.5    # Saturation conservation
LAMBDA_MASS = 0.2   # Mass conservation
LAMBDA_DARCY = 0.1  # Darcy flow constraint
```

---

## Quick Start Guide

### 1. Run Best Model (ConvLSTM with Scheduled Sampling)

```bash
cd "/Users/narjisse/Documents/Effat Courses/deeponet/final_codes_github"
python3 01_ConvLSTM_UNet_ScheduledSampling.py
```

**Expected runtime**: ~24 hours on Mac M1 CPU

**Output**:
- Training/validation losses per epoch
- Final model: `../checkpoints/convlstm_ss_best.pt`
- Results: R¬≤ = 0.990 on 15-month rollout

### 2. Run All Baselines

```bash
# Teacher Forcing only (fails on rollout)
python3 02_ConvLSTM_UNet_TeacherForcing.py

# 3D U-Net without temporal memory
python3 03_3D_UNet_Baseline.py

# FNO spectral method
python3 04_FNO_Baseline.py
```

### 3. Run Ablation Studies

```bash
# Remove saturation loss
python3 ablation_A.py

# Remove mass loss
python3 ablation_B.py

# Remove Darcy loss
python3 ablation_C.py
```

---

## File Sizes

```
Total size: ~260 KB (Python scripts only)

01_ConvLSTM_UNet_ScheduledSampling.py    33 KB  (main model)
02_ConvLSTM_UNet_TeacherForcing.py       28 KB
03_3D_UNet_Baseline.py                   26 KB
04_FNO_Baseline.py                       31 KB
ablation_A.py                            33 KB
ablation_B.py                            33 KB
ablation_C.py                            33 KB
config_shared.py                          5 KB
verify_consistency.py                     5 KB
README_CODES.md                           8 KB
```

---

## What Makes These Codes "GitHub-Ready"?

‚úÖ **Consistent configurations** - All use same SEED, split, hyperparameters
‚úÖ **Same parameter count** - All ~21M parameters for fair comparison
‚úÖ **Well documented** - Clear README with results tables
‚úÖ **Verified** - Automated verification script confirms consistency
‚úÖ **Self-contained** - Each script runs independently
‚úÖ **Local-compatible** - Mac M1 CPU mode, no GPU needed
‚úÖ **Reproducible** - Fixed seed=42, deterministic training

---

## Expected Results Table

| Model | Architecture | Single-step R¬≤ | 15-month R¬≤ | Inference (33 steps) |
|-------|-------------|----------------|-------------|---------------------|
| ConvLSTM SS ‚≠ê | U-Net + LSTM + Scheduled Sampling | 0.997 | **0.990** ‚úÖ | 1.5 sec |
| ConvLSTM TF | U-Net + LSTM + Teacher Forcing | 0.997 | 0.071 ‚ùå | 1.5 sec |
| 3D U-Net | U-Net without LSTM | 0.806 | -0.55 ‚ùå | 1.2 sec |
| FNO | Spectral method | 0.896 | -4.40 ‚ùå | 2.1 sec |

**Key findings**:
1. ‚úÖ **Scheduled sampling is critical** (0.990 vs 0.071)
2. ‚úÖ **Temporal memory is essential** (ConvLSTM vs plain UNet)
3. ‚úÖ **Spatial CNN > spectral methods** for this problem

---

## Next Steps for GitHub

1. ‚úÖ All codes created with consistent configs
2. ‚úÖ Verification script confirms consistency
3. ‚úÖ Documentation (README) complete
4. ‚è≠Ô∏è Copy this folder to your GitHub repository:

```bash
# Initialize git (if not done)
cd "/Users/narjisse/Documents/Effat Courses/deeponet"
git add final_codes_github/
git commit -m "Add final training codes with consistent configurations"
git push origin main
```

---

## Contact

**Narjisse Kabbaj**
Energy Research Lab, College of Engineering
Effat University, Jeddah, Saudi Arabia
Email: nkabbaj@effatuniversity.edu.sa

---

**Last updated**: January 1, 2026
