"""
CONFIGURATION PARTAG√âE POUR TOUS LES MOD√àLES
===================================================
GARANTIT LA COH√âRENCE ENTRE TOUS LES MOD√àLES POUR COMPARAISON √âQUITABLE

Utilis√© par:
- ConvLSTM U-Net avec Scheduled Sampling
- ConvLSTM U-Net avec Teacher Forcing only
- 3D U-Net Baseline (sans m√©moire temporelle)
- FNO 3D Baseline

Version: LOCAL MAC M1
"""

import random
import numpy as np
import torch
from pathlib import Path

# ============================================================================
# SEED POUR REPRODUCTIBILIT√â EXACTE
# ============================================================================
SEED = 42

def set_seed(seed=SEED):
    """Fixe tous les seeds pour reproductibilit√©"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"üé≤ SEED = {seed} (r√©sultats reproductibles)")

# ============================================================================
# CHEMINS LOCAL MAC
# ============================================================================
DATA_PATH = Path('/Users/narjisse/Documents/Effat Courses/deeponet')
CHECKPOINT_DIR = DATA_PATH / 'checkpoints'
CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)

# ============================================================================
# SPLIT DES DONN√âES (IDENTIQUE POUR TOUS)
# ============================================================================
TRAIN_SPLIT = 0.70  # 70% pour training
VAL_SPLIT = 0.15    # 15% pour validation
TEST_SPLIT = 0.15   # 15% pour test

# ============================================================================
# HYPERPARAM√àTRES PARTAG√âS
# ============================================================================

# Architecture (pour avoir ~21M param√®tres dans chaque mod√®le)
BASE_FEATURES = 32  # Pour ConvLSTM U-Net et 3D U-Net
FNO_WIDTH = 32      # Pour FNO
FNO_MODES = [8, 8, 4]  # modes1, modes2, modes3

# Training
NUM_EPOCHS = 40
BATCH_SIZE = 1  # N√©cessaire pour 3D avec m√©moire limit√©e
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-5

# Scheduled Sampling (pour ConvLSTM SS uniquement)
SCHEDULED_SAMPLING_K = 5
PURE_ROLLOUT_START_EPOCH = 31  # Epochs 31-40 en pure autoregressive

# S√©quences
SEQUENCE_LENGTH_TRAIN = 10  # Pendant training
SEQUENCE_LENGTH_TEST = 33   # Pendant √©valuation (15 mois complets)

# Physics-informed loss weights
LAMBDA_SAT = 0.5   # Saturation conservation
LAMBDA_MASS = 0.2  # Mass conservation
LAMBDA_DARCY = 0.1 # Darcy flow

# Gradient clipping
GRAD_CLIP_NORM = 1.0

# ============================================================================
# DEVICE CONFIGURATION (MAC M1)
# ============================================================================

def get_device():
    """D√©tecte et retourne le device appropri√© pour Mac M1"""
    if torch.backends.mps.is_available():
        # MPS ne supporte pas ConvTranspose3d, donc on utilise CPU
        device = torch.device("cpu")
        print("‚ö†Ô∏è  Apple Silicon d√©tect√© mais MPS non utilisable")
        print("   Raison: ConvTranspose3d non support√© sur MPS")
        print("   Utilisation: CPU")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"‚úÖ CUDA GPU d√©tect√©: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device("cpu")
        print("‚ö†Ô∏è  CPU mode")

    print(f"\nDevice: {device}")
    return device

# ============================================================================
# COMPTE DE PARAM√àTRES
# ============================================================================

def count_parameters(model):
    """Compte le nombre de param√®tres entra√Ænables"""
    total = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\nüìä Nombre de param√®tres: {total:,}")
    print(f"   ({total/1e6:.2f}M param√®tres)")
    return total

# ============================================================================
# V√âRIFICATION DE LA COH√âRENCE
# ============================================================================

def verify_config():
    """V√©rifie que la configuration est coh√©rente"""
    print("\n" + "="*70)
    print("CONFIGURATION PARTAG√âE - V√âRIFICATION")
    print("="*70)
    print(f"SEED: {SEED}")
    print(f"Split: {TRAIN_SPLIT:.0%} / {VAL_SPLIT:.0%} / {TEST_SPLIT:.0%}")
    print(f"Epochs: {NUM_EPOCHS}")
    print(f"Learning rate: {LEARNING_RATE}")
    print(f"Batch size: {BATCH_SIZE}")
    print(f"Sequence length (train): {SEQUENCE_LENGTH_TRAIN}")
    print(f"Sequence length (test): {SEQUENCE_LENGTH_TEST}")
    print(f"\nArchitecture:")
    print(f"  Base features (ConvLSTM/UNet): {BASE_FEATURES}")
    print(f"  FNO width: {FNO_WIDTH}")
    print(f"  FNO modes: {FNO_MODES}")
    print(f"\nLoss weights:")
    print(f"  Œª_sat: {LAMBDA_SAT}")
    print(f"  Œª_mass: {LAMBDA_MASS}")
    print(f"  Œª_darcy: {LAMBDA_DARCY}")
    print(f"\nData path: {DATA_PATH}")
    print(f"Checkpoints: {CHECKPOINT_DIR}")
    print("="*70 + "\n")

    # V√©rifier que les splits totalisent 100%
    assert abs(TRAIN_SPLIT + VAL_SPLIT + TEST_SPLIT - 1.0) < 1e-6, "Splits doivent totaliser 100%"

    return True

if __name__ == "__main__":
    verify_config()
    set_seed()
    device = get_device()
